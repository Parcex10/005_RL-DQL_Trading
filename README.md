#### Autores: AdriÃ¡n Herrera, Patrick F. BÃ¡rcena y Carlos Moreno

ğŸ§  Deep Q-Learning aplicado a Trading AlgorÃ­tmico
Este proyecto implementa un agente de Deep Q-Learning (DQL) para la toma de decisiones en un entorno de trading. El objetivo fue entrenar un modelo que aprende a comprar, vender o mantener posiciones en acciones de Microsoft (MSFT) mediante un proceso de exploraciÃ³n y explotaciÃ³n, y luego comparar su desempeÃ±o contra una estrategia tradicional Buy & Hold.

ğŸ¯ Objetivo
Desarrollar un agente basado en Reinforcement Learning capaz de maximizar el rendimiento de una inversiÃ³n a travÃ©s de decisiones secuenciales, evaluando mÃ©tricas financieras clave como rendimiento total, volatilidad, drawdown mÃ¡ximo y Sharpe Ratio.

ğŸ§ª Resumen del Experimento
Agente Q-Learning bÃ¡sico: Entrenado con 100 episodios para entender la mecÃ¡nica del entorno.

Agente Deep Q-Learning (DQL): VersiÃ³n robusta entrenada con 500 episodios para capturar patrones complejos del mercado.

ComparaciÃ³n: Backtesting del agente en datos reales y contraste contra Buy & Hold.

Resultados Destacados:

| MÃ©trica                    | Buy & Hold | DQL          |
| -------------------------- | ---------- | ------------ |
| Rendimiento Total (%)      | +368%      | **+46,977%** |
| Max Drawdown (%)           | -37.15%    | **-5.67%**   |
| Volatilidad Anualizada (%) | 30.12%     | **11.86%**   |
| Sharpe Ratio               | 1.00       | **8.74**     |

âš™ï¸ TecnologÃ­as Usadas
Python 3.x

PyTorch (entrenamiento del agente DQL)

Pandas, NumPy, Matplotlib (anÃ¡lisis y visualizaciÃ³n)

Jupyter Notebook (desarrollo y presentaciÃ³n del proyecto)

ğŸ—‚ï¸ Estructura del Proyecto:

005_RL-DQL_Trading/

â”œâ”€â”€ data/      # Datos histÃ³ricos de MSFT

â”‚   â””â”€â”€ MSFT_5yr.csv

â”œâ”€â”€ models/           # Pesos del modelo DQL entrenado

â”‚   â””â”€â”€ dql_model.pth

â”œâ”€â”€ notebooks/        # Notebook principal con el anÃ¡lisis completo

â”‚   â””â”€â”€ report.ipynb

â”œâ”€â”€ utils/            # CÃ³digo del agente DQL

â”‚   â””â”€â”€ rl_agent.py

â”œâ”€â”€ README.md         # DescripciÃ³n del proyecto

â””â”€â”€ requirements.txt  # Dependencias necesarias

ğŸš€ CÃ³mo Ejecutar

1ï¸âƒ£ Clona el repositorio:
git clone <URL_del_repo>
cd 005_RL-DQL_Trading

2ï¸âƒ£ Instala las dependencias:
pip install -r requirements.txt

3ï¸âƒ£ Abre el notebook:
jupyter notebook notebooks/report.ipynb



